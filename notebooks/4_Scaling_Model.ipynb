{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73a9c12-b053-4227-9fce-3801289bf63c",
   "metadata": {},
   "source": [
    "# ðŸš€ Part 4: To Infinity and Beyond!\n",
    "We are going to re-run the key cells used to set up our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61881d5b-bfee-4ecf-90cc-76cdb38e7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import torch \n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "from helper import helper\n",
    "\n",
    "random.seed(2021) # We set a seed to ensure our samples will be the same every time we run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fe030e-f8b3-4fba-9c31-5c50bbae6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the function without running it\n",
    "def load_data_fashion_mnist(batch_size, n_workers):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\",\n",
    "                                                    train=True,\n",
    "                                                    transform=trans,\n",
    "                                                    download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\",\n",
    "                                                   train=False,\n",
    "                                                   transform=trans,\n",
    "                                                   download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=n_workers),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=n_workers))\n",
    "\n",
    "# Then execute the function here\n",
    "batch_size = 1024  # Set to 256 on your own device\n",
    "n_workers = 0      # Set to 4 on your own device\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size, n_workers = n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532f43e6-0632-4f9f-af27-0b22f5f96ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise LeNet Architecture (ans)\n",
    "net = nn.Sequential(nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size=5), nn.Sigmoid(),\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "                    nn.Linear(in_features = 16 * 5 * 5, out_features = 120), nn.Sigmoid(),\n",
    "                    nn.Linear(in_features = 120, out_features = 84), nn.Sigmoid(), \n",
    "                    nn.Linear(in_features = 84, out_features = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d107d5e-7b62-4b95-98af-86eca4853ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d: # We will only set the weights from linear and Conv2d layers, since pooling layers do not require this\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights) # nb: this takes in a function as an argument\n",
    "\n",
    "lr = 0.9 \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr) \n",
    "loss = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fc421-0938-4066-9662-128c90b07099",
   "metadata": {},
   "source": [
    "## Scaling for Training\n",
    "### Mini-batches\n",
    "When we train our model, we often split our dataset into **mini-batches**. Kind of like if you order a huge pizza, you can't eat it all at once, the neural network will struggle to train all the data at once. Let's think of two extremes of mini-batches:\n",
    "* *Very Small:* suppose you have only one example per mini-batch, you are going to update your network after every single training example. This is very unstable for the training algorithm (it's like trying to survey one person and then using those results to represent the whole Australian population!) it's difficult to know how to update your weights to improve the model with just one example.\n",
    "* *Very Large:* suppose you have the entire dataset as your mini-batch, you are going to update your network after it evaluates every single example. This will be slow and take up a lot of memory.\n",
    "\n",
    "Just like with many things in life, there is a trade-off. We have selected a batch-size of `1024` (`256` if you are using your own device) earlier on as we read in the data.\n",
    "\n",
    "### Epochs\n",
    "We also train our neural network over our dataset many times. It's like when you first meet someone, you might struggle to recall their face, but after meeting them many more times, the face becomes very familiar to you. Each time we train over our entire dataset is called an **epoch**.  \n",
    "* Too few epochs and the model does not get a chance to capture the patterns in the data.\n",
    "* Too many epochs and the model overfits and will not generalise well (we shall see an example later).\n",
    "\n",
    "The `num_epochs` variable below captures how many epochs we want to train over (set this to `10` if you are using your own device).\n",
    "\n",
    "**Warning:** The code below will take around 10 minutes to run (depending on the number of epochs). Feel free to grab a coffee while you wait.\n",
    "\n",
    "![](../images/train_time.png)\n",
    "\n",
    "([source](https://www.reddit.com/r/ProgrammerHumor/comments/9cu51a/shamelessly_stolen_from_xkcd_credit_where_is_due/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a62085e3-cbce-41fa-9448-804099137e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5 # Set this to 10 if you are using your own device\n",
    "epochs = np.arange(num_epochs) + 1\n",
    "\n",
    "def train_network_scaled(net, num_epochs):\n",
    "    timer = helper.Timer() \n",
    "    # Keep track of accuracy for each epoch\n",
    "    train_accuracy = np.array([])\n",
    "    test_accuracy = np.array([])\n",
    "\n",
    "    print(\"=== Starting Neural Network Training Now ===\")\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = helper.Accumulator(3) # define a 3d accumulator\n",
    "        net.train() # set to train\n",
    "        for i, (X, y) in enumerate(train_iter): # Loop thru each mini-batch\n",
    "            timer.start()\n",
    "            optimizer.zero_grad() # before running the forward/backward pass we need to reset the gradient (otherwise it accumulates)\n",
    "            y_hat = net(X) # Forward pass on the data to make prediction\n",
    "            l = loss(y_hat, y) # calculate the loss \n",
    "            l.backward() # back propagate the loss\n",
    "            optimizer.step() # step forward in optimisation\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], helper.accuracy(y_hat, y), X.shape[0]) # mini-batch loss,  # matches, # total examples\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2] # loss per unit \n",
    "            train_acc = metric[1] / metric[2] # training accuracy\n",
    "        test_acc = helper.evaluate_accuracy(net, test_iter)\n",
    "\n",
    "        train_accuracy = np.append(train_accuracy, train_acc)\n",
    "        test_accuracy = np.append(test_accuracy, test_acc)\n",
    "        print(\"Epoch Number\", epoch, \"Trained --\", f'{timer.sum():.1f} cumulative sec taken ')\n",
    "\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{timer.sum():.1f} sec taken ')\n",
    "    \n",
    "    return (train_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c6efee-1410-4881-8012-4377ad9b9f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Neural Network Training Now ===\n",
      "Epoch Number 0 Trained -- 4.1 cumulative sec taken \n",
      "Epoch Number 1 Trained -- 8.1 cumulative sec taken \n",
      "Epoch Number 2 Trained -- 12.2 cumulative sec taken \n",
      "Epoch Number 3 Trained -- 16.7 cumulative sec taken \n",
      "Epoch Number 4 Trained -- 21.0 cumulative sec taken \n",
      "loss 0.522, train acc 0.800, test acc 0.796\n",
      "21.0 sec taken \n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = train_network_scaled(net = net, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "371c0a45-9397-4ac8-be1f-9c8124431297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot it\n",
    "plt.plot(epochs, train_accuracy, label = \"Training Accuracy\")\n",
    "plt.plot(epochs, test_accuracy, label = \"Testing Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"# Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6797f4-349e-400c-addf-c234543f5306",
   "metadata": {},
   "source": [
    "With around 5 epochs, you can see that our performance on *both* train and test set have improved considerably from ~10% to around 40-50%. These are still not great, but we have now reached the limits of binder.\n",
    "\n",
    "If you are using your own machine, I highly encourage you to try 25-30 epochs. We should be able to reach accuracies of almost 80-90% with sufficient training on our LeNet. For instructions on how to do that, refer to the description in the main [github page](https://github.com/bbpi2/cnn-pytorch-tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce92ad-8620-4f7c-87b1-53288d4ff43a",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='#F89536'> **Discussion:** </font> \n",
    "How did that compare with our previous model? How does that compare with random assignment? What can be done to improve the model?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e032144-deca-4dd5-82ae-4b79bc2472ff",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "We have talked a lot about how overfitting is bad, but how do we actually tell when a model has overfitted? Recall that:\n",
    "> Overfitting = performs well on data it's trained on but cannot generalise to unseen data (eg. test)\n",
    "\n",
    "So if your train accuracy improves but the test accuracy plateaus, then you know you have overfitted! See the example below for a model trained on 500 epochs:\n",
    "\n",
    "![overfit](../images/overfit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8eeca6-adc7-4d82-a757-ec6157919b3e",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color='#F89536'> **Discussion:** </font> \n",
    "What is the optimal number of epochs from the graph above?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bf112-b14b-49c7-b931-977f6c5e3841",
   "metadata": {},
   "source": [
    "# ðŸ““ Appendix\n",
    "\n",
    "## <font color='red'> A Lesson on Data Structures: `DataLoader` vs. `DataSet` </font>\n",
    "PyTorch natively provides two data structures to work with. `DataLoader` and `DataSet`. Here's a bit of comparison:\n",
    "\n",
    "| `DataSet` | `DataLoader` |\n",
    "| --- | --- |\n",
    "| Typical dataset object (like a table) | An iterator object |\n",
    "| Reads in all the data at once and stores in memory | Reads in data only when the function is called |\n",
    "| Good for smaller datasets | Good for larger datasets |\n",
    "\n",
    "When working with big data, it becomes essential to use an iterator like the `DataLoader` object, since we rarely have enough memory to store the 10-20GB of data (not do we need to)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b21df4-9eb4-4b12-b0f1-99879df297f4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-tutorial",
   "language": "python",
   "name": "cnn-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
